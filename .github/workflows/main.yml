name: epglaozhang

on:
  schedule:
    - cron: "0 0 * * *"  # 每天午夜执行（可调整）
  workflow_dispatch:     # 允许手动触发

jobs:
  scraping-job:
    runs-on: ubuntu-latest
    steps:
      # 1. 检出代码
      - name: Checkout code
        uses: actions/checkout@v3

      # 2. 设置 Python 环境（3.10 版本）
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.10"

      # 3. 安装依赖库（包括 requests、Django、BeautifulSoup4）
      - name: Install dependencies
        run: |
          pip install requests django beautifulsoup4
          # 如果有其他依赖项，可添加到 requirements.txt 并使用 pip install -r requirements.txt

      # 4. 执行默认抓取任务（使用 SQLite3 数据库）
      - name: Scrape default data
        run: python main.py
        env:
          # Django 的数据库配置（使用 SQLite3 默认路径）
          DJANGO_SETTINGS_MODULE: your_project.settings  # 替换为你的 Django 项目 settings 模块路径

      # 5. 执行全频道抓取任务
      - name: Scrape all channels
        run: python main.py -channel
        env:
          DJANGO_SETTINGS_MODULE: your_project.settings

      # 可选：添加错误处理
      - name: Check exit status
        if: ${{ failure() }}
        run: echo "任务执行失败，请检查日志"
